{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41af0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ADLS config\n",
    "spark.conf.set(\n",
    "    \"fs.azure.account.key.hospitalstorageaccnt.dfs.core.windows.net\",\n",
    "    dbutils.secrets.get(scope=\"hospitalkeyvault\", key=\"storage-conn\")\n",
    ")\n",
    "\n",
    "bronze_path = \"abfss://bronze@hospitalstorageaccnt.dfs.core.windows.net/patient_flow\"\n",
    "silver_path = \"abfss://silver@hospitalstorageaccnt.dfs.core.windows.net/patient_flow\"\n",
    "\n",
    "# Read stream from Bronze\n",
    "bronze_df = (\n",
    "    spark.readStream\n",
    "    .format(\"delta\")\n",
    "    .load(bronze_path)\n",
    ")\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"patient_id\", StringType()),\n",
    "    StructField(\"gender\", StringType()),\n",
    "    StructField(\"age\", IntegerType()),\n",
    "    StructField(\"department\", StringType()),\n",
    "    StructField(\"admission_time\", StringType()),\n",
    "    StructField(\"discharge_time\", StringType()),\n",
    "    StructField(\"bed_id\", IntegerType()),\n",
    "    StructField(\"hospital_id\", IntegerType())\n",
    "])\n",
    "\n",
    "# Parse raw json\n",
    "parse_df = bronze_df.withColumn(\"data\", from_json(col(\"raw_json\"), schema)).select(\"data.*\")\n",
    "\n",
    "# Clean time columns\n",
    "clean_df = parse_df.withColumn(\"admission_time\", to_timestamp(\"admission_time\"))\n",
    "clean_df = clean_df.withColumn(\"discharge_time\", to_timestamp(\"discharge_time\"))\n",
    "\n",
    "clean_df = clean_df.withColumn(\n",
    "    \"admission_time\",\n",
    "    when(\n",
    "        col(\"admission_time\").isNull() | (col(\"admission_time\") > current_timestamp()),\n",
    "        current_timestamp()\n",
    "    ).otherwise(col(\"admission_time\"))\n",
    ")\n",
    "\n",
    "# Fix age\n",
    "clean_df = clean_df.withColumn(\n",
    "    \"age\",\n",
    "    when(\n",
    "        col(\"age\") >= 100,\n",
    "        floor(rand() * 90 + 1).cast(\"int\")\n",
    "    ).otherwise(col(\"age\"))\n",
    ")\n",
    "\n",
    "# Ensure all expected columns exist\n",
    "expected_cols = [\"patient_id\", \"gender\", \"age\", \"department\", \"admission_time\", \"discharge_time\", \"bed_id\", \"hospital_id\"]\n",
    "\n",
    "for col_name in expected_cols:\n",
    "    if col_name not in clean_df.columns:\n",
    "        clean_df = clean_df.withColumn(col_name, lit(None))\n",
    "\n",
    "# Write to Silver\n",
    "(\n",
    "    clean_df\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"mergeSchema\", \"true\")\n",
    "    .option(\"checkpointLocation\", silver_path + \"_checkpoint\")\n",
    "    .start(silver_path)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba791a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(spark.read.format(\"delta\").load(silver_path))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
